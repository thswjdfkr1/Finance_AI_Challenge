{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1440,"status":"ok","timestamp":1756356545346,"user":{"displayName":"손정락","userId":"10892662232752168928"},"user_tz":-540},"id":"yeQYtuNOtQFk","outputId":"c4bbe69e-2dac-43cb-938d-9d861dcbc1e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"feWpLq5_tSDO"},"outputs":[],"source":["# !pip install -U langchain-community\n","# !pip install -U transformers\n","# !pip install -U bitsandbytes accelerate\n","# # !pip install datasets\n","# !pip install pypdf\n","# !pip install peft\n","# !pip install langchain\n","# !pip install langchain-huggingface faiss-cpu\n","# !pip install rank_bm25\n","# !pip install langchain-huggingface"]},{"cell_type":"code","source":["# !pip install --upgrade --force-reinstall autoawq --extra-index-url https://download.pytorch.org/whl/cu121\n","# !pip uninstall -y autoawq\n","# !git clone https://github.com/casper-hansen/AutoAWQ.git\n","# %cd AutoAWQ\n","# !pip install ."],"metadata":{"id":"bRqQojg8r03P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import json\n","import torch\n","import pandas as pd\n","import numpy as np\n","import glob\n","\n","import tqdm\n","from statistics import mean\n","from datasets import Dataset, load_dataset\n","from typing import List, Dict\n","\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","from peft import PeftModelForCausalLM\n","from peft import AutoPeftModelForCausalLM\n","from peft import prepare_model_for_kbit_training\n","\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, pipeline, BitsAndBytesConfig\n","from transformers import EarlyStoppingCallback\n","from transformers import default_data_collator\n","\n","from langchain.document_loaders import PyPDFLoader\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain.retrievers import BM25Retriever, EnsembleRetriever\n","from langchain_community.vectorstores import FAISS\n","from langchain_huggingface import HuggingFaceEmbeddings\n","from langchain_core.prompts import PromptTemplate\n","from langchain_core.documents import Document\n","from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n","from langchain_community.llms import HuggingFacePipeline\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","\n","from rank_bm25 import BM25Okapi\n","import pickle\n","\n","from google.colab import files\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"x4nWSxzyq-2b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# retriever"],"metadata":{"id":"tYlxmcMarHq8"}},{"cell_type":"markdown","source":["## pdf load & split chunks"],"metadata":{"id":"u-nb33ROnP4P"}},{"cell_type":"code","source":["# pdf 로드\n","pdf_folder = \"/content/drive/MyDrive/1데이콘/2025금융AIChallenge금융AI모델경쟁/dataset/pdf/*.pdf\"\n","pdf_files = glob.glob(pdf_folder)"],"metadata":{"id":"U27PcKp9m3oe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_chunks = []\n","\n","def split_chunks(pdf_files):\n","  for pdf_file in tqdm.tqdm(pdf_files, desc = 'Pdf Load'):\n","    loader = PyPDFLoader(pdf_file)\n","    docs = loader.load()\n","\n","    # 불필요한 문자 제거\n","    pattern = r'[①-⑳◆·「」｢｣□◦\\-\\*❶-❸Ⅲ※‧Ÿ]'\n","    for doc in docs:\n","      text = doc.page_content\n","      text = re.sub(pattern, ' ', text)\n","      text = re.sub(r'\\n', ' ', text)\n","      text = re.sub(r'\\s+', ' ', text)\n","      text = text.strip()\n","      doc.page_content = text\n","\n","    paragraph_lengths = [len(doc.page_content) for doc in docs]\n","\n","    print()\n","    print(\"문단 개수:\", len(paragraph_lengths))\n","    print(\"평균 문단 길이:\", round(mean(paragraph_lengths)))\n","    print(\"최소 문단 길이:\", min(paragraph_lengths))\n","    print(\"최대 문단 길이:\", max(paragraph_lengths))\n","\n","    # 추천 chunk_size & overlap 계산\n","    avg_len = mean(paragraph_lengths)\n","    max_len = max(paragraph_lengths)\n","\n","    # chunk_size는 최대 문단 길이보다 조금 크게, 평균의 2~3배 정도로 설정\n","    chunk_size = int(min(max_len * 1.1, avg_len * 3))\n","    chunk_overlap = int(chunk_size * 0.15)  # 15% 정도 겹치기\n","\n","    print(\"추천 chunk_size:\", chunk_size)\n","    print(\"추천 chunk_overlap:\", chunk_overlap)\n","\n","    text_spliter = RecursiveCharacterTextSplitter(\n","      chunk_size = chunk_size,\n","      chunk_overlap = chunk_overlap,\n","      separators = [\"\\n\\n\", \"\\n\", \" \", \"\"]\n","      )\n","\n","    split_chunks = text_spliter.split_documents(docs)\n","    print(\"청크의 수 :\", len(split_chunks))\n","    all_chunks.extend(split_chunks)"],"metadata":{"id":"471G9zk6olzE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["split_chunks(pdf_files)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"3pLdI3XXtyD9","executionInfo":{"status":"ok","timestamp":1756356638045,"user_tz":-540,"elapsed":69917,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"cf989c33-e052-4a6f-c837-80e00670a59a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Pdf Load:   8%|▊         | 1/12 [00:13<02:31, 13.80s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","문단 개수: 28\n","평균 문단 길이: 1494\n","최소 문단 길이: 55\n","최대 문단 길이: 3228\n","추천 chunk_size: 3550\n","추천 chunk_overlap: 532\n","청크의 수 : 28\n"]},{"output_type":"stream","name":"stderr","text":["Pdf Load:  25%|██▌       | 3/12 [00:18<00:42,  4.70s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","문단 개수: 112\n","평균 문단 길이: 514\n","최소 문단 길이: 0\n","최대 문단 길이: 1167\n","추천 chunk_size: 1283\n","추천 chunk_overlap: 192\n","청크의 수 : 99\n","\n","문단 개수: 17\n","평균 문단 길이: 1629\n","최소 문단 길이: 1019\n","최대 문단 길이: 1996\n","추천 chunk_size: 2195\n","추천 chunk_overlap: 329\n","청크의 수 : 17\n","\n","문단 개수: 6\n","평균 문단 길이: 1439\n","최소 문단 길이: 178\n","최대 문단 길이: 1780\n","추천 chunk_size: 1958\n","추천 chunk_overlap: 293\n","청크의 수 : 6\n"]},{"output_type":"stream","name":"stderr","text":["\rPdf Load:  42%|████▏     | 5/12 [00:19<00:14,  2.13s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","문단 개수: 21\n","평균 문단 길이: 1878\n","최소 문단 길이: 1405\n","최대 문단 길이: 2093\n","추천 chunk_size: 2302\n","추천 chunk_overlap: 345\n","청크의 수 : 21\n"]},{"output_type":"stream","name":"stderr","text":["\rPdf Load:  50%|█████     | 6/12 [00:19<00:09,  1.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","문단 개수: 36\n","평균 문단 길이: 1776\n","최소 문단 길이: 982\n","최대 문단 길이: 2336\n","추천 chunk_size: 2569\n","추천 chunk_overlap: 385\n","청크의 수 : 36\n"]},{"output_type":"stream","name":"stderr","text":["\rPdf Load:  58%|█████▊    | 7/12 [00:19<00:06,  1.28s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","문단 개수: 34\n","평균 문단 길이: 1427\n","최소 문단 길이: 248\n","최대 문단 길이: 1761\n","추천 chunk_size: 1937\n","추천 chunk_overlap: 290\n","청크의 수 : 34\n"]},{"output_type":"stream","name":"stderr","text":["\rPdf Load:  67%|██████▋   | 8/12 [00:20<00:04,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","문단 개수: 44\n","평균 문단 길이: 1819\n","최소 문단 길이: 388\n","최대 문단 길이: 2271\n","추천 chunk_size: 2498\n","추천 chunk_overlap: 374\n","청크의 수 : 44\n"]},{"output_type":"stream","name":"stderr","text":["\rPdf Load:  75%|███████▌  | 9/12 [00:20<00:02,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","문단 개수: 41\n","평균 문단 길이: 1788\n","최소 문단 길이: 878\n","최대 문단 길이: 2187\n","추천 chunk_size: 2405\n","추천 chunk_overlap: 360\n","청크의 수 : 41\n"]},{"output_type":"stream","name":"stderr","text":["\rPdf Load:  83%|████████▎ | 10/12 [00:52<00:20, 10.11s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","문단 개수: 732\n","평균 문단 길이: 986\n","최소 문단 길이: 0\n","최대 문단 길이: 2910\n","추천 chunk_size: 2956\n","추천 chunk_overlap: 443\n","청크의 수 : 720\n"]},{"output_type":"stream","name":"stderr","text":["\rPdf Load:  92%|█████████▏| 11/12 [01:07<00:11, 11.55s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","문단 개수: 166\n","평균 문단 길이: 837\n","최소 문단 길이: 0\n","최대 문단 길이: 1588\n","추천 chunk_size: 1746\n","추천 chunk_overlap: 261\n","청크의 수 : 163\n"]},{"output_type":"stream","name":"stderr","text":["Pdf Load: 100%|██████████| 12/12 [01:09<00:00,  5.83s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","문단 개수: 63\n","평균 문단 길이: 433\n","최소 문단 길이: 0\n","최대 문단 길이: 1092\n","추천 chunk_size: 1201\n","추천 chunk_overlap: 180\n","청크의 수 : 61\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## build retriever"],"metadata":{"id":"Q49U-d9iU7lH"}},{"cell_type":"code","source":["def build_retriever(all_chunks,\n","                               embedding_model: str = \"sentence-transformers/all-mpnet-base-v2\"\n","                               ):\n","  # FAISS retriever\n","  embeddings = HuggingFaceEmbeddings(model_name=embedding_model,\n","                                     cache_folder=\"/content/drive/MyDrive/1데이콘/2025금융AIChallenge금융AI모델경쟁/dataset/faiss_embedding_models\")\n","  vectordb = FAISS.from_documents(all_chunks, embeddings)\n","  vector_retriever = vectordb.as_retriever(search_type = 'mmr',\n","                                    search_kwargs = {'k':5, 'fetch_k': 20, 'lambda_mult': 0.5}\n","                                    )\n","\n","  # BM25 retriever\n","  tokenized_docs = [doc.page_content.split() for doc in all_chunks]\n","  bm25_okapi = BM25Okapi(tokenized_docs)\n","  bm25_retriever = BM25Retriever.from_documents(all_chunks)\n","\n","  return embeddings, vectordb, vector_retriever, bm25_okapi, bm25_retriever"],"metadata":{"id":"fsTb2tozug9_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["faiss_embeddings, faiss_vectordb, faiss_vector_retriever, bm25_okapi, bm25_retriever = build_retriever(all_chunks)"],"metadata":{"id":"KkXd-NZZwQ5_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# vectordb (FAISS 인덱스) 저장\n","\n","# faiss_retriever 내부의 vectorstore 가져오기\n","faiss_vectordb.save_local(\"/content/drive/MyDrive/1데이콘/2025금융AIChallenge금융AI모델경쟁/dataset/faiss_vectordb\")\n","\n","# bm25_retriever 내부의 vectorstore 가져오기\n","with open(\"/content/drive/MyDrive/1데이콘/2025금융AIChallenge금융AI모델경쟁/dataset/bm25_vectordb/bm25_model.pkl\", \"wb\") as f:\n","    pickle.dump(bm25_okapi, f)"],"metadata":{"id":"y7trANKe3mL2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model load & Quantization"],"metadata":{"id":"gu6XPIXqmJeb"}},{"cell_type":"code","source":["model_name = 'LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct'\n","\n","# 양자화\n","# bnb_config = BitsAndBytesConfig(\n","#     load_in_4bit = True,\n","#     bnb_4bit_quant_type = \"nf4\",\n","#     bnb_4bit_use_double_quant = True,\n","#     bnb_4bit_compute_dtype = torch.bfloat16\n","# )\n","\n","# awq_config = AWQConfig(\n","#     bits=8,\n","#     group_size=128,\n","#     module_skip_list=[\"lm_head\"]\n","# )\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    device_map={\"\":0},\n","    trust_remote_code=True,\n","    # quantization_config = bnb_config\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# 그래디언트 체크포인팅 활성화(메모리 절약)\n","model.gradient_checkpointing_enable()\n","\n","# 모델을 훈련에 적합하게 조성\n","model = prepare_model_for_kbit_training(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["f1db379ca9154e5ca8864e897357cf62","a93041fcbe054a21b915d958e235256b","5ff804881593465db80f4eb2f1192ed2","ced8420646854dfbb2c958e2a4ea5b22","306981369a6f44799a1aa746c50d082c","acd7148d1bff4e96b1ed4a145d611c3e","3a3c2d1975994d0cb601c8ce7b7eb787","d52a7ee26d3c4950b9e2614750460a1a","6310add956104b1d84cdcb2e2cde063f","dbdd3a352da7438f8f5d47042f38e868","2fa365d171d547d4a5ba8c9d386d3c48"]},"id":"LDY9mAk8md6K","executionInfo":{"status":"ok","timestamp":1756356707053,"user_tz":-540,"elapsed":16237,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"900b2349-2b2d-4182-d310-10b84563a637"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1db379ca9154e5ca8864e897357cf62"}},"metadata":{}}]},{"cell_type":"code","source":["# for name, module in model.named_modules():\n","#     if \"attn\" in name.lower() or \"attention\" in name.lower():\n","#         print(name)"],"metadata":{"id":"wKatNVCems6x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LoRA 설정\n","lora_config = LoraConfig(\n","    lora_alpha = 32,\n","    lora_dropout = 0.1,\n","    r = 16,\n","    task_type=\"CAUSAL_LM\",\n","    bias = \"none\",\n","    target_modules = [\n","        # 'query_key_value'\n","        'q_proj',\n","        'k_proj',\n","        'v_proj',\n","        'o_proj'\n","    ]\n","  )\n","\n","# 모델에 LoRA 적용\n","model = get_peft_model(model, lora_config)\n","\n","# 훈련 가능한 파라미터 확인\n","model.print_trainable_parameters()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgxqOnwCmlC6","executionInfo":{"status":"ok","timestamp":1756356708961,"user_tz":-540,"elapsed":1888,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"896e59b8-b0bb-40a7-9a72-09183fbbb91b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 9,437,184 || all params: 7,827,886,080 || trainable%: 0.1206\n"]}]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"FCcfbg_yqzTt"}},{"cell_type":"markdown","source":["## Define Untils"],"metadata":{"id":"SVYGvWLJDRAc"}},{"cell_type":"code","source":["# 객관식 여부 판단 함수\n","def is_multiple_choice(question_text):\n","    \"\"\"\n","    객관식 여부를 판단: 2개 이상의 숫자 선택지가 줄 단위로 존재할 경우 객관식으로 간주\n","    \"\"\"\n","    lines = question_text.strip().split(\"\\n\")\n","    option_count = sum(bool(re.match(r\"^\\s*[1-9]?\\s\", line)) for line in lines)\n","    return option_count >= 2"],"metadata":{"id":"TGO1KwJBDRPo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 질문과 선택지 분리 함수\n","def extract_question_and_choices(full_text):\n","    \"\"\"\n","    전체 질문 문자열에서 질문 본문과 선택지 리스트를 분리\n","    \"\"\"\n","    lines = full_text.strip().split(\"\\n\")\n","    q_lines = []\n","    options = []\n","\n","    for line in lines:\n","        if re.match(r\"^\\s*[1-9]?\\s\", line):\n","            options.append(line.strip())\n","        else:\n","            q_lines.append(line.strip())\n","\n","    question = \" \".join(q_lines)\n","    return question, options"],"metadata":{"id":"PaTVmBFpkblO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 후처리 함수\n","def extract_answer_only(generated_text: str, original_question: str) -> str:\n","    \"\"\"\n","    - \"답변:\" 이후 텍스트만 추출\n","    - 객관식 문제면: 정답 숫자만 추출 (실패 시 전체 텍스트 또는 기본값 반환)\n","    - 주관식 문제면: 전체 텍스트 그대로 반환\n","    - 공백 또는 빈 응답 방지: 최소 \"미응답\" 반환\n","    \"\"\"\n","    # \"답변:\" 기준으로 텍스트 분리\n","    if \"답변:\" in generated_text:\n","        text = generated_text.split(\"답변:\")[-1].strip()\n","    else:\n","        text = generated_text.strip()\n","\n","    # 공백 또는 빈 문자열일 경우 기본값 지정\n","    if not text:\n","        return \"미응답\"\n","\n","    # 객관식 여부 판단\n","    is_mc = is_multiple_choice(original_question)\n","\n","    if is_mc:\n","        # 숫자만 추출\n","        match = re.match(r\"\\D*([1-9]?)\", text)\n","        # match = re.search(r\"([1-9]?)\", text)\n","        if match:\n","            return match.group(1)\n","        else:\n","            # 숫자 추출 실패 시 \"0\" 반환\n","            return \"0\"\n","    else:\n","        return text"],"metadata":{"id":"H-W1PrM1kc7_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 하이브리드 검색기\n","def hybrid_search(question: str, top_k: int, bm25_weight: int, faiss_weight: int):\n","  # bm25 점수\n","  tokenized_question = question.split()\n","  bm25_scores = bm25_okapi.get_scores(tokenized_question)\n","  bm25_scores_norm = bm25_scores / (np.max(bm25_scores) + 1e-8)\n","\n","  # faiss 점수\n","  ques_embedding = faiss_embeddings.embed_query(question)\n","  D, I = faiss_vectordb.index.search(np.array([ques_embedding]), len(all_chunks))\n","  faiss_scores = np.zeros(len(all_chunks))\n","  faiss_scores[I[0]] = (np.max(D[0]) - D[0]) / (np.max(D[0]) - np.min(D[0]) + 1e-8)\n","\n","  # 가중합\n","  combined_scores = bm25_weight * bm25_scores_norm + faiss_weight * faiss_scores\n","\n","  # Top-K 문서 선택\n","  top_indices = np.argsort(combined_scores)[::-1][:top_k]\n","  top_docs = [all_chunks[i] for i in top_indices]\n","\n","  return top_docs, combined_scores"],"metadata":{"id":"Bw-c5RUOYmeh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 프롬프트 생성기\n","def make_prompt_auto(text: str, top_docs: str) -> str:\n","    \"\"\"RAG 컨텍스트를 포함해 객관식/주관식 프롬프트를 자동 구성\"\"\"\n","    if is_multiple_choice(text):\n","        question, options = extract_question_and_choices(text)\n","        prompt = (\n","            \"당신은 금융보안 전문가입니다.\\n\"\n","            \"아래 질문에 대해 적절한 **정답 선택지 번호만 출력**하세요. 다른 단어/설명 금지.\\n\\n\"\n","            \"예: 1 / 2/ 3/ 4/ 5\\n\\n\"\n","            f\"참고문서: {top_docs}\\n\\n\"\n","            f\"질문: {question}\\n\"\n","            \"선택지:\\n\"\n","            f\"{'\\n'.join(options)}\\n\\n\"\n","            \"답변:\"\n","        )\n","    else:\n","        prompt = (\n","            \"당신은 금융보안 전문가입니다.\\n\"\n","            \"아래 주관식 질문에 대해 정확하고 간략한 설명을 작성하세요.\\n\\n\"\n","            \"단, 참고 문서를 바탕으로 답을 구성하되 검색된 내용을 그대로 복사하지 말고 반드시 **재구성, 요약, 재작성**해서 답변해야 합니다.\\n\\n\"\n","            f\"참고문서: {top_docs}\\n\\n\"\n","            f\"질문: {text}\\n\\n\"\n","            \"답변:\"\n","        )\n","    return prompt"],"metadata":{"id":"okD_Ro4GDSNQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Finetunning Model Load"],"metadata":{"id":"pLe295SWDVbW"}},{"cell_type":"code","source":["adapter_path = \"/content/drive/MyDrive/1데이콘/2025금융AIChallenge금융AI모델경쟁/dataset/finetunning_model8/checkpoint-1104\"\n","\n","# 추론만 고려\n","fine_model = PeftModelForCausalLM.from_pretrained(model, adapter_path)\n","fine_model = fine_model.merge_and_unload().to(\"cuda\")"],"metadata":{"id":"X3OLPaFtDUEC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 추가 파인튜닝\n","# fine_model = AutoPeftModelForCausalLM.from_pretrained(\n","#     adapter_path,\n","#     torch_dtype=\"auto\",\n","#     device_map=\"auto\"\n","# )\n","\n","# fine_model = PeftModelForCausalLM.from_pretrained(model, adapter_path)\n","# fine_model = fine_model.merge_and_unload()\n","\n","# # 여기서 다시 로드 (Hugging Face 방식)\n","# fine_model.save_pretrained(\"merged_model\")\n","# tokenizer.save_pretrained(\"merged_model\")\n","\n","# from transformers import AutoModelForCausalLM, AutoTokenizer\n","# fine_model = AutoModelForCausalLM.from_pretrained(\"merged_model\").to(\"cuda\")\n","# tokenizer = AutoTokenizer.from_pretrained(\"merged_model\")\n","\n","# pipe = pipeline(\"text-generation\", model=fine_model, tokenizer=tokenizer)\n","\n","\n","# pipe = pipeline(\"text-generation\",\n","#                 model=fine_model,\n","#                 tokenizer=tokenizer)"],"metadata":{"id":"vXSzD6FL3vqq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test data Load\n"],"metadata":{"id":"V7dz4wzFDKFf"}},{"cell_type":"code","source":["test = pd.read_csv('/content/drive/MyDrive/1데이콘/2025금융AIChallenge금융AI모델경쟁/dataset/test.csv')"],"metadata":{"id":"Feg0XGML1EpK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inference"],"metadata":{"id":"369cf6UcDYxq"}},{"cell_type":"code","source":["def inference(question, fine_model, tokenizer, faiss_vectordb, bm25_okapi,\n","              top_k: int, bm25_weight: int, faiss_weight: int):\n","\n","  top_docs = hybrid_search(question, top_k, bm25_weight, faiss_weight)\n","  prompt = make_prompt_auto(question, top_docs)\n","  inputs = tokenizer(prompt, return_tensors = 'pt').to('cuda')\n","\n","  # 객관식\n","  if is_multiple_choice(question):\n","    output_ids = fine_model.generate(\n","        **inputs,\n","        max_new_tokens=128,\n","        do_sample=False,\n","    )\n","  else:\n","    output_ids = fine_model.generate(\n","        **inputs,\n","        max_new_tokens=256,\n","        do_sample=True,\n","        temperature=0.3,\n","        top_p=0.9\n","      )\n","\n","  output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","  pred_answer = extract_answer_only(output_text, original_question=q)\n","\n","  return pred_answer"],"metadata":{"id":"GBg5UhrymsCC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","\n","preds = []\n","\n","for q in tqdm.tqdm(test['Question'], desc='Inference'):\n","  answer = inference(q, fine_model, tokenizer, faiss_vectordb, bm25_okapi,\n","              top_k=7, bm25_weight=0.1, faiss_weight=0.9)\n","  preds.append(answer)"],"metadata":{"id":"xTquOF3qoG28","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756366582540,"user_tz":-540,"elapsed":3248652,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"fbf97d67-f382-47d2-c11d-b32cca4e7c45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Inference: 100%|██████████| 515/515 [54:08<00:00,  6.31s/it]\n"]}]},{"cell_type":"markdown","source":["# Submission"],"metadata":{"id":"FOYZgsR2DcLg"}},{"cell_type":"code","source":["sample_submission = pd.read_csv('/content/drive/MyDrive/1데이콘/2025금융AIChallenge금융AI모델경쟁/dataset/sample_submission.csv')\n","sample_submission['Answer'] = preds\n","sample_submission.to_csv('/content/drive/MyDrive/1데이콘/2025금융AIChallenge금융AI모델경쟁/submission_final.csv', index=False, encoding='utf-8-sig')\n","sample_submission.to_csv('submission_final.csv', index=False, encoding='utf-8-sig')\n","\n","files.download('submission_final.csv')"],"metadata":{"id":"LKJtVEtRDeTz","executionInfo":{"status":"ok","timestamp":1756366582564,"user_tz":-540,"elapsed":16,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"c407131c-4c46-44d8-a62b-3f7ecebdb561"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_76227d89-3043-426d-ab8c-0d6b86173a1a\", \"submission_final.csv\", 17175)"]},"metadata":{}}]},{"cell_type":"code","source":["preds"],"metadata":{"id":"_aKTI6Kb1C3v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ShlrNgEy1GYZ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1bHMS8sQ2RskrVyqPWfRkKxBpTxXJKiN_","timestamp":1754887030566}],"collapsed_sections":["u-nb33ROnP4P","Q49U-d9iU7lH","SVYGvWLJDRAc","pLe295SWDVbW"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}